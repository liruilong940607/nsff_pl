{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import os\n",
    "import torch\n",
    "from utils import *\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "from models.rendering import *\n",
    "from models.nerf import *\n",
    "\n",
    "import metrics\n",
    "\n",
    "from datasets import dataset_dict, flowlib, ray_utils\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "img_wh = (360, 480)\n",
    "root_dir = '/home/ruilongli/workspace/nsff_pl/data'\n",
    "\n",
    "dataset = dataset_dict['monocular'](root_dir, 'test', img_wh=img_wh, start_end=(0, 163))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def f(rays, ts, **kwargs):\n",
    "    \"\"\"Do batched inference on rays using chunk.\"\"\"\n",
    "    B = rays.shape[0]\n",
    "    results = defaultdict(list)\n",
    "    for i in range(0, B, chunk):\n",
    "        kwargs_ = {}\n",
    "        for k, v in kwargs.items():\n",
    "            if k in ['t_embedded', 'a_embedded']: kwargs_[k] = v[i:i+chunk]\n",
    "            else: kwargs_[k] = v\n",
    "        rendered_ray_chunks = \\\n",
    "            render_rays(models,\n",
    "                        embeddings,\n",
    "                        rays[i:i+chunk],\n",
    "                        ts[i:i+chunk],\n",
    "                        dataset.N_frames-1,\n",
    "                        N_samples,\n",
    "                        0,\n",
    "                        0,\n",
    "                        N_importance,\n",
    "                        chunk,\n",
    "                        test_time=True,\n",
    "                        **kwargs_)\n",
    "\n",
    "        for k, v in rendered_ray_chunks.items(): results[k] += [v.cpu()]\n",
    "    for k, v in results.items(): results[k] = torch.cat(v, 0)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = 'ckpts/exp/epoch=3.ckpt'\n",
    "\n",
    "\n",
    "N_vocab = 163\n",
    "N_tau = 48\n",
    "N_samples = 128\n",
    "N_importance = 0\n",
    "chunk = 1024*16\n",
    "\n",
    "embedding_xyz = PosEmbedding(9, 10)\n",
    "embedding_dir = PosEmbedding(3, 4)\n",
    "embeddings = {'xyz': embedding_xyz, 'dir': embedding_dir}\n",
    "embedding_t = torch.nn.Embedding(N_vocab, N_tau).cuda()\n",
    "load_ckpt(embedding_t, ckpt_path, model_name='embedding_t')\n",
    "embeddings['t'] = embedding_t\n",
    "\n",
    "\n",
    "nerf_fine = NeRF('fine',\n",
    "                 in_channels_xyz=6*10+3,\n",
    "                 encode_transient=True,\n",
    "                 in_channels_t=N_tau,\n",
    "                 output_flow=True,\n",
    "                 flow_scale=0.2).cuda()\n",
    "load_ckpt(nerf_fine, ckpt_path, 'nerf_fine')\n",
    "models = {'fine': nerf_fine}\n",
    "\n",
    "if N_importance > 0:\n",
    "    nerf_coarse = NeRF('coarse',\n",
    "                       in_channels_xyz=6*10+3,\n",
    "                       encode_transient=encode_transient,\n",
    "                       in_channels_t=N_tau).cuda()\n",
    "    load_ckpt(nerf_coarse, ckpt_path, 'nerf_coarse')\n",
    "    models['coarse'] = nerf_coarse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.spatial.transform.rotation import Rotation\n",
    "# dataset.poses_test[8, 1, 3] += 0.1\n",
    "# dataset.poses_test[20,:3,:3] = dataset.poses_test[0,:3,:3]@Rotation.from_euler('x', -3, degrees=True).as_matrix()\n",
    "\n",
    "sample = dataset[8] # select pose\n",
    "rays = sample['rays']\n",
    "ts = sample['ts']*0+8 # select time\n",
    "output_transient = True\n",
    "output_transient_flow = []\n",
    "if dataset.flow_fw_paths: output_transient_flow += ['fw']\n",
    "if dataset.flow_bw_paths: output_transient_flow += ['bw']\n",
    "kwargs = {'output_transient': output_transient,\n",
    "          'output_transient_flow': output_transient_flow}\n",
    "\n",
    "t = time.time()\n",
    "results = f(rays.cuda(), ts.cuda(), **kwargs)\n",
    "torch.cuda.synchronize()\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from kornia import create_meshgrid\n",
    "\n",
    "try: img_gt = sample['rgbs'].view(img_wh[1], img_wh[0], 3)\n",
    "except: pass\n",
    "img_pred = np.clip(results['rgb_fine'].view(img_wh[1], img_wh[0], 3).cpu().numpy(), 0, 1)\n",
    "try:\n",
    "    grid = create_meshgrid(img_wh[1], img_wh[0], normalized_coordinates=False)[0]\n",
    "    if 'fw' in kwargs['output_transient_flow']:\n",
    "        xyz_fw_w = ray_utils.ndc2world(results['transient_xyz_fw'].cpu(), dataset.Ks[sample['cam_ids']]).unsqueeze(-1)\n",
    "        ts_fw = torch.clamp(ts+1, max=dataset.N_frames-1)\n",
    "        Ps_fw = dataset.Ps[sample['cam_ids'], ts_fw] # (N_rays, 3, 4)\n",
    "        uvd_fw = Ps_fw[:, :3, :3] @ xyz_fw_w + Ps_fw[:, :3, 3:]\n",
    "        uv_fw = uvd_fw[:, :2, 0] / uvd_fw[:, 2:, 0] # (N_rays, 2)\n",
    "        uv_fw = uv_fw.view(img_wh[1], img_wh[0], 2) - grid\n",
    "    if 'bw' in kwargs['output_transient_flow']:\n",
    "        xyz_bw_w = ray_utils.ndc2world(results['transient_xyz_bw'].cpu(), dataset.Ks[sample['cam_ids']]).unsqueeze(-1)\n",
    "        ts_bw = torch.clamp(ts-1, min=0)\n",
    "        Ps_bw = dataset.Ps[sample['cam_ids'], ts_bw] # (N_rays, 3, 4)\n",
    "        uvd_bw = Ps_bw[:, :3, :3] @ xyz_bw_w + Ps_bw[:, :3, 3:]\n",
    "        uv_bw = uvd_bw[:, :2, 0] / uvd_bw[:, 2:, 0] # (N_rays, 2)\n",
    "        uv_bw = uv_bw.view(img_wh[1], img_wh[0], 2) - grid\n",
    "except: pass\n",
    "img_pred_ = Image.fromarray((img_pred*255).astype(np.uint8))\n",
    "depth_pred = results['depth_fine'].view(img_wh[1], img_wh[0])\n",
    "depth_pred_ = visualize_depth(depth_pred).permute(1,2,0).numpy()\n",
    "\n",
    "plt.subplots(figsize=(15, 9))\n",
    "plt.tight_layout()\n",
    "plt.subplot(331)\n",
    "plt.title('img_GT')\n",
    "try: plt.imshow(img_gt)\n",
    "except: pass\n",
    "plt.subplot(332)\n",
    "plt.title('img_pred')\n",
    "plt.imshow(img_pred_)\n",
    "plt.subplot(333)\n",
    "plt.title('depth_pred')\n",
    "plt.imshow(depth_pred_)\n",
    "try:\n",
    "    plt.subplot(334)\n",
    "    plt.title('flow_fw_GT')\n",
    "    plt.imshow(flowlib.flow_to_image(sample['flow_fw']))\n",
    "except: plt.imshow(255*np.ones((img_wh[1], img_wh[0], 3), np.uint8))\n",
    "try:\n",
    "    plt.subplot(335)\n",
    "    plt.title('flow_fw_pred')\n",
    "    plt.imshow(flowlib.flow_to_image(uv_fw.numpy()))\n",
    "except: pass\n",
    "if dataset.disp_paths:\n",
    "    plt.subplot(336)\n",
    "    plt.title('depth_GT')\n",
    "    plt.imshow(sample['disp'].reshape(img_wh[1], img_wh[0]), 'jet')\n",
    "try:\n",
    "    plt.subplot(337)\n",
    "    plt.title('flow_bw_GT')\n",
    "    plt.imshow(flowlib.flow_to_image(sample['flow_bw']))\n",
    "except: plt.imshow(255*np.ones((img_wh[1], img_wh[0], 3), np.uint8))\n",
    "try:\n",
    "    plt.subplot(338)\n",
    "    plt.title('flow_bw_pred')\n",
    "    plt.imshow(flowlib.flow_to_image(uv_bw.numpy()))\n",
    "except: pass\n",
    "plt.show()\n",
    "\n",
    "try:\n",
    "    print('PSNR between GT and pred:', metrics.psnr(img_gt, img_pred).item())\n",
    "    print('SSIM between GT and pred in mask:', metrics.ssim(img_gt, torch.from_numpy(img_pred)).item(), '\\n')\n",
    "except: pass\n",
    "if dataset.mask_paths:\n",
    "    mask = sample['mask'].view(img_wh[1], img_wh[0])\n",
    "    if (mask==1).any():\n",
    "        try:\n",
    "            print('PSNR between GT and pred in mask:', metrics.psnr(img_gt, img_pred, mask==0).item())\n",
    "            print('SSIM between GT and pred in mask:', metrics.ssim(img_gt, torch.from_numpy(img_pred), mask==0).item(), '\\n')\n",
    "        except: pass\n",
    "\n",
    "if output_transient:\n",
    "    img_pred_static = np.clip(results['_static_rgb_fine'].view(img_wh[1], img_wh[0], 3).cpu().numpy(), 0, 1)\n",
    "    img_pred_transient = np.clip(results['transient_rgb_fine'].view(img_wh[1], img_wh[0], 3).cpu().numpy(), 0, 1)\n",
    "    depth_pred_static = results['_static_depth_fine'].view(img_wh[1], img_wh[0]).cpu()\n",
    "    # depth_pred_transient = results['_transient_depth_fine'].view(img_wh[1], img_wh[0]).cpu()\n",
    "    dynamicness = results['transient_alpha_fine'].view(img_wh[1], img_wh[0]).cpu()\n",
    "    plt.subplots(figsize=(15, 6))\n",
    "    plt.tight_layout()\n",
    "    plt.subplot(231)\n",
    "    plt.title('static')\n",
    "    plt.imshow(img_pred_static)\n",
    "    plt.subplot(232)\n",
    "    plt.title('dynamic (gray=transparent!)')\n",
    "    plt.imshow(img_pred_transient)\n",
    "    plt.subplot(233)\n",
    "    plt.title('dynamicness')\n",
    "    plt.imshow(dynamicness, 'bone')\n",
    "    plt.subplot(234)\n",
    "    plt.title('static depth')\n",
    "    plt.imshow(visualize_depth(depth_pred_static).permute(1,2,0))\n",
    "    plt.subplot(235)\n",
    "    plt.title('dynamic depth')\n",
    "    # plt.imshow(visualize_depth(depth_pred_transient).permute(1,2,0))\n",
    "    # plt.subplot(236)\n",
    "    plt.title('dynamic mask')\n",
    "    plt.imshow(mask==0, 'bone')\n",
    "    plt.show()\n",
    "    print('PSNR between GT and static:', metrics.psnr(img_gt, img_pred_static).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "66700fafe166c6c2871238b6e7e324ab04992c8251e8d18ed3be82016ee53104"
  },
  "kernelspec": {
   "display_name": "nerf_pl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
