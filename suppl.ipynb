{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/facebookresearch/detectron2/blob/master/projects/DensePose/densepose/vis/base.py\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "class TextVisualizer(object):\n",
    "\n",
    "    _COLOR_GRAY = (218, 227, 218)\n",
    "    _COLOR_WHITE = (255, 255, 255)\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        font_face=cv2.FONT_HERSHEY_DUPLEX,\n",
    "        font_color_bgr=_COLOR_GRAY,\n",
    "        font_scale=0.35,\n",
    "        font_line_type=cv2.LINE_AA,\n",
    "        font_line_thickness=1,\n",
    "        font_scale_with_image=False,\n",
    "        fill_color_bgr=_COLOR_WHITE,\n",
    "        fill_color_transparency=1.0,\n",
    "        frame_color_bgr=_COLOR_WHITE,\n",
    "        frame_color_transparency=1.0,\n",
    "        frame_thickness=1,\n",
    "    ):\n",
    "        self.font_face = font_face\n",
    "        self.font_color_bgr = font_color_bgr\n",
    "        self.font_scale = font_scale\n",
    "        self.font_line_type = font_line_type\n",
    "        self.font_line_thickness = font_line_thickness\n",
    "        self.font_scale_with_image = font_scale_with_image\n",
    "        self.fill_color_bgr = fill_color_bgr\n",
    "        self.fill_color_transparency = fill_color_transparency\n",
    "        self.frame_color_bgr = frame_color_bgr\n",
    "        self.frame_color_transparency = frame_color_transparency\n",
    "        self.frame_thickness = frame_thickness\n",
    "\n",
    "    def visualize(self, image_bgr, txt, topleft_xy):\n",
    "        txt_w, txt_h, txt_bsl = self.get_text_size_wh(txt, image_bgr.shape[:2])\n",
    "        topleft_xy = tuple(map(int, topleft_xy))\n",
    "        bottomleft_xy = (topleft_xy[0], topleft_xy[1] + txt_h)\n",
    "        txt_h += txt_bsl\n",
    "        x, y = topleft_xy\n",
    "        if self.frame_color_transparency < 1.0:\n",
    "            t = self.frame_thickness\n",
    "            image_bgr[y - t : y + txt_h + t, x - t : x + txt_w + t, :] = (\n",
    "                image_bgr[y - t : y + txt_h + t, x - t : x + txt_w + t, :]\n",
    "                * self.frame_color_transparency\n",
    "                + np.array(self.frame_color_bgr) * (1.0 - self.frame_color_transparency)\n",
    "            ).astype(np.float)\n",
    "        if self.fill_color_transparency < 1.0:\n",
    "            image_bgr[y : y + txt_h, x : x + txt_w, :] = (\n",
    "                image_bgr[y : y + txt_h, x : x + txt_w, :]\n",
    "                * self.fill_color_transparency\n",
    "                + np.array(self.fill_color_bgr) * (1.0 - self.fill_color_transparency)\n",
    "            ).astype(np.float)\n",
    "        cv2.putText(\n",
    "            image_bgr,\n",
    "            txt,\n",
    "            bottomleft_xy,\n",
    "            self.font_face,\n",
    "            self.get_font_scale(image_bgr.shape[:2]),\n",
    "            self.font_color_bgr,\n",
    "            self.font_line_thickness,\n",
    "            self.font_line_type,\n",
    "        )\n",
    "        return image_bgr\n",
    "\n",
    "    def get_font_scale(self, image_hw):\n",
    "        font_scale = self.font_scale\n",
    "        if self.font_scale_with_image:\n",
    "            font_scale = max(font_scale * min(image_hw[0], image_hw[1]) / 512, 0.2)\n",
    "        return font_scale\n",
    "\n",
    "    def get_text_size_wh(self, txt, image_hw):\n",
    "        ((txt_w, txt_h), txt_bsl) = cv2.getTextSize(\n",
    "            txt,\n",
    "            self.font_face,\n",
    "            self.get_font_scale(image_hw),\n",
    "            self.font_line_thickness,\n",
    "        )\n",
    "        return txt_w, txt_h, txt_bsl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NSFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dir = \"/home/ruilongli/data/NSFF/nvidia_data_full/\"\n",
    "frame_dir = \"/home/ruilongli/workspace/nsff_pl/data/\"\n",
    "video_names = [\"Balloon1-2\", \"Balloon2-2\", \"DynamicFace-2\", \"Jumping\", \"Playground\", \"Skating-2\", \"Truck-2\", \"Umbrella\"]\n",
    "fps_list = [15, 30, 15, 30, 30, 30, 30, 15]\n",
    "cameras = [\"cam%02d\" % i for i in range(1, 12 + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imageio\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "text_visualizer = TextVisualizer(\n",
    "    font_color_bgr=(0, 0, 0),\n",
    "    font_scale=2,\n",
    "    font_line_thickness=4,\n",
    "    fill_color_transparency=0.3,\n",
    "    font_scale_with_image=True,\n",
    ")\n",
    "\n",
    "\n",
    "for video_name, fps in zip(video_names, fps_list):\n",
    "    video_frames = sorted(\n",
    "        os.listdir(os.path.join(video_dir, video_name, \"dense\", \"mv_images\"))\n",
    "    )\n",
    "    images_multiview = []\n",
    "    for i, camera in enumerate(cameras):\n",
    "        images = []\n",
    "        for video_frame in video_frames:\n",
    "            image_path = os.path.join(\n",
    "                video_dir, video_name, \"dense\", \"mv_images\", video_frame, \"%s.jpg\" % camera\n",
    "            )\n",
    "            image = imageio.imread(image_path)\n",
    "            # image = cv2.resize(image, (0, 0), fx=0.5, fy=0.5)\n",
    "            images.append(text_visualizer.visualize(image, \"capture%d\" % i, (0, 0)))\n",
    "        images_multiview.append(images)\n",
    "    images_multiview = np.array(images_multiview)\n",
    "\n",
    "    frames = sorted(\n",
    "        os.listdir(os.path.join(video_dir, video_name, \"dense\", \"images\"))\n",
    "    )\n",
    "    images_train = []\n",
    "    for frame in frames:\n",
    "        image_path = os.path.join(video_dir, video_name, \"dense\", \"images\", frame)\n",
    "        image = imageio.imread(image_path)\n",
    "        image = cv2.resize(image, (0, 0), fx=2, fy=2)\n",
    "        images_train.append(text_visualizer.visualize(image, \"train traj.\", (0, 0)))\n",
    "    images_train = np.stack(images_train)\n",
    "\n",
    "    canvas = np.concatenate([\n",
    "        np.concatenate([\n",
    "            images_multiview[0],\n",
    "            images_multiview[4],\n",
    "        ], axis=-3),\n",
    "        np.concatenate([\n",
    "            images_multiview[2],\n",
    "            images_multiview[6],\n",
    "        ], axis=-3),\n",
    "        np.zeros((images_train.shape[0], images_train.shape[1], 10, 3), dtype=images_train.dtype) + 255,\n",
    "        images_train,\n",
    "    ], axis=-2)\n",
    "\n",
    "    writer = imageio.get_writer(\"suppl/%s.mp4\" % video_name, fps=fps)\n",
    "    for img in canvas:\n",
    "        img = cv2.resize(img, (0, 0), fx=0.3, fy=0.3)\n",
    "        writer.append_data(img)\n",
    "    writer.close()\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nerfies & HyperNeRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nerfies_dir = \"/home/ruilongli/data/nerfies/\"\n",
    "hypernerf_dir = \"/home/ruilongli/data/hypernerf/\"\n",
    "nerfies_names = [\"broom\", \"tail\", \"toby-sit\"]\n",
    "hypernerf_names = [\"broom2\", \"vrig-3dprinter\", \"vrig-chicken\", \"vrig-peel-banana\"]\n",
    "fps = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imageio\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "\n",
    "text_visualizer = TextVisualizer(\n",
    "    font_color_bgr=(0, 0, 0),\n",
    "    font_scale=2,\n",
    "    font_line_thickness=4,\n",
    "    fill_color_transparency=0.3,\n",
    "    font_scale_with_image=True,\n",
    ")\n",
    "\n",
    "\n",
    "for video_name in nerfies_names + hypernerf_names:\n",
    "    if video_name in nerfies_names:\n",
    "        data_dir = nerfies_dir\n",
    "    else:\n",
    "        data_dir = hypernerf_dir\n",
    "    \n",
    "    image_dir = os.path.join(data_dir, video_name, \"rgb\", \"2x\")\n",
    "    with open(os.path.join(data_dir, video_name, \"dataset.json\"), \"r\") as fp:\n",
    "        meta_data = json.load(fp)\n",
    "    ids = meta_data[\"ids\"]\n",
    "    train_ids = meta_data[\"train_ids\"]\n",
    "    left_ids = [\n",
    "        id for id in ids if \n",
    "        (\n",
    "            (\"left\" in id) and\n",
    "            os.path.exists(os.path.join(image_dir, \"left1_%s.png\" % id.split(\"_\")[1])) and\n",
    "            os.path.exists(os.path.join(image_dir, \"right1_%s.png\" % id.split(\"_\")[1]))\n",
    "        )\n",
    "    ]\n",
    "    right_ids = [\n",
    "        id for id in ids if \n",
    "        (\n",
    "            (\"right\" in id) and\n",
    "            os.path.exists(os.path.join(image_dir, \"left1_%s.png\" % id.split(\"_\")[1])) and\n",
    "            os.path.exists(os.path.join(image_dir, \"right1_%s.png\" % id.split(\"_\")[1]))\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    images_multiview = []\n",
    "    for i, subset_ids in enumerate([left_ids, right_ids]):\n",
    "        images = []\n",
    "        for id in subset_ids:\n",
    "            image_path = os.path.join(image_dir, \"%s.png\" % id)\n",
    "            if not os.path.exists(image_path):\n",
    "                continue\n",
    "            image = imageio.imread(image_path)\n",
    "            images.append(text_visualizer.visualize(image, \"capture%d\" % i, (0, 0)))\n",
    "        images_multiview.append(images)\n",
    "    images_multiview = np.array(images_multiview)\n",
    "\n",
    "    images_train = []\n",
    "    for id in train_ids:\n",
    "        image_path = os.path.join(image_dir, \"%s.png\" % id)\n",
    "        if not os.path.exists(image_path):\n",
    "            continue\n",
    "        image = imageio.imread(image_path)\n",
    "        images_train.append(text_visualizer.visualize(image, \"train traj.\", (0, 0)))\n",
    "    images_train = np.stack(images_train)\n",
    "    print (images_multiview.shape, images_train.shape)\n",
    "\n",
    "    canvas = np.concatenate([\n",
    "        images_multiview[0],\n",
    "        images_multiview[1],\n",
    "        np.zeros((images_train.shape[0], images_train.shape[1], 10, 3), dtype=images_train.dtype) + 255,\n",
    "        images_train,\n",
    "    ], axis=-2)\n",
    "\n",
    "    writer = imageio.get_writer(\"suppl/%s.mp4\" % video_name, fps=fps)\n",
    "    for img in canvas:\n",
    "        img = cv2.resize(img, (0, 0), fx=0.3, fy=0.3)\n",
    "        writer.append_data(img)\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/ruilongli/workspace/nerfbios/datasets/iphone-captures_v3\"\n",
    "video_names = [\n",
    "    \"hang-dance-1_0-250-1_aligned_gq95_bk120\",\n",
    "    \"block-move_0-350-1_aligned_gq95_bk120\",\n",
    "    \"teddy-move_0-350-1_aligned_gq95_bk120\",\n",
    "    \"wheel-rotate_0-250-1_aligned_gq95_bk120\",\n",
    "]\n",
    "fps = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imageio\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "\n",
    "text_visualizer = TextVisualizer(\n",
    "    font_color_bgr=(0, 0, 0),\n",
    "    font_scale=1.5,\n",
    "    # fill_color_bgr=(128, 128, 128),\n",
    "    font_line_thickness=2,\n",
    "    fill_color_transparency=0.3,\n",
    "    font_scale_with_image=True,\n",
    ")\n",
    "\n",
    "\n",
    "for video_name in video_names:\n",
    "    image_dir = os.path.join(data_dir, video_name, \"rgb\", \"2x\")\n",
    "    with open(os.path.join(data_dir, video_name, \"dataset.json\"), \"r\") as fp:\n",
    "        meta_data = json.load(fp)\n",
    "    train_ids = meta_data[\"train_ids\"]\n",
    "\n",
    "    images_multiview = []\n",
    "    for i, camera in enumerate([\"000\", \"001\"]):\n",
    "        images = []\n",
    "        for id in train_ids:\n",
    "            image_path = os.path.join(image_dir, \"2_%s_%s.png\" % (camera, id.split(\"_\")[-1]))\n",
    "            if not os.path.exists(image_path):\n",
    "                image = np.zeros((480, 360, 3), dtype=np.uint8) + 128\n",
    "            else:\n",
    "                image = imageio.imread(image_path)\n",
    "            images.append(text_visualizer.visualize(image, \"capture (test)\", (0, 0)))\n",
    "        images_multiview.append(images)\n",
    "    images_multiview = np.array(images_multiview)\n",
    "\n",
    "    images_train = []\n",
    "    for id in train_ids:\n",
    "        image_path = os.path.join(image_dir, \"%s.png\" % id)\n",
    "        image = imageio.imread(image_path)\n",
    "        images_train.append(text_visualizer.visualize(image, \"capture (train)\", (0, 0)))\n",
    "    images_train = np.stack(images_train)\n",
    "    print (images_multiview.shape, images_train.shape)\n",
    "\n",
    "    if video_name == \"wheel-rotate_0-250-1_aligned_gq95_bk120\":\n",
    "        canvas = np.concatenate([\n",
    "            images_multiview[0],\n",
    "            np.zeros((images_train.shape[0], images_train.shape[1], 10, 3), dtype=images_train.dtype) + 255,\n",
    "            images_train,\n",
    "        ], axis=-2)\n",
    "    else:\n",
    "        canvas = np.concatenate([\n",
    "            images_multiview[0],\n",
    "            images_multiview[1],\n",
    "            np.zeros((images_train.shape[0], images_train.shape[1], 10, 3), dtype=images_train.dtype) + 255,\n",
    "            images_train,\n",
    "        ], axis=-2)\n",
    "\n",
    "    writer = imageio.get_writer(\"suppl/%s.mp4\" % video_name, fps=fps)\n",
    "    for img in canvas:\n",
    "        # img = cv2.resize(img, (0, 0), fx=0.3, fy=0.3)\n",
    "        writer.append_data(img)\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapy\n",
    "\n",
    "mediapy.show_video(images_multiview[0], height=100, codec='gif', fps=15)\n",
    "# images_multiview.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediapy.show_video(canvas, height=100, codec='gif', fps=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapy\n",
    "\n",
    "mediapy.show_video(images_multiview[0], height=100, codec='gif', fps=15)\n",
    "# images_multiview.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediapy.show_video(images_multiview[6], height=100, codec='gif', fps=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediapy.show_video(images_train, height=100, codec='gif', fps=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_multiview.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "66700fafe166c6c2871238b6e7e324ab04992c8251e8d18ed3be82016ee53104"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('nsff_pl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
